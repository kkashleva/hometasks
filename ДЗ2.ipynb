{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adab17fc",
   "metadata": {},
   "source": [
    "### Задание 2\n",
    "Преобразуйте таблицу с абсолютными частотностями в семинарской тетрадке в таблицу с tfidf значениями. (Таблица - https://i.ibb.co/r5Nc2HC/abs-bow.jpg) Формула tfidf есть в семинаре на картнике с пояснениями на английском. Считать нужно в питоне. Формат итоговой таблицы может быть любым, главное, чтобы был код и можно было воспроизвести вычисления."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "01d4cdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "8dab48f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>я</th>\n",
       "      <th>ты</th>\n",
       "      <th>и</th>\n",
       "      <th>только</th>\n",
       "      <th>не</th>\n",
       "      <th>он</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>я и ты</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ты и я</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>я я и только я</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>только не я</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>он</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             text  я  ты  и  только  не  он\n",
       "0          я и ты  1   1  1       0   0   0\n",
       "1          ты и я  1   1  1       0   0   0\n",
       "2  я я и только я  3   0  1       1   0   0\n",
       "3     только не я  1   0  0       1   1   0\n",
       "4              он  0   0  0       0   0   1"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#исходная таблица\n",
    "data = pd.read_csv('таблица.csv')\n",
    "data.rename(columns={'Unnamed: 0': 'text', 'Unnamed: 1': 'я', 'Unnamed: 2': 'ты', 'Unnamed: 3': 'и', 'Unnamed: 4' : 'только', 'Unnamed: 5' : 'не', 'Unnamed: 6' : 'он'}, inplace=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "1336e5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"таблица1.txt\", 'r', encoding='utf8')\n",
    "corpus = f.read().splitlines()\n",
    "doc1, doc2, doc3, doc4, doc5 = corpus\n",
    "doc1 = doc1.split(' ')\n",
    "doc2 = doc2.split(' ')\n",
    "doc3 = doc3.replace(',', '').split(' ')\n",
    "doc4 = doc4.split(' ')\n",
    "doc5 = doc5.split(' ')\n",
    "\n",
    "uniqueWords = set(doc1).union(set(doc2)).union(set(doc3)).union(set(doc4)).union(set(doc5))\n",
    "numOfWords1 = dict.fromkeys(uniqueWords, 0)\n",
    "for word in doc1:\n",
    "    numOfWords1[word] += 1\n",
    "numOfWords2 = dict.fromkeys(uniqueWords, 0)\n",
    "for word in doc2:\n",
    "    numOfWords2[word] += 1\n",
    "numOfWords3 = dict.fromkeys(uniqueWords, 0)\n",
    "for word in doc3:\n",
    "    numOfWords3[word] += 1\n",
    "numOfWords4 = dict.fromkeys(uniqueWords, 0)\n",
    "for word in doc4:\n",
    "    numOfWords4[word] += 1\n",
    "numOfWords5 = dict.fromkeys(uniqueWords, 0)\n",
    "for word in doc5:\n",
    "    numOfWords5[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "e4bf7d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'и', 'ты', 'я', 'он', 'не', 'только'}\n"
     ]
    }
   ],
   "source": [
    "print(uniqueWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "398b61b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'и': 1, 'ты': 1, 'я': 1, 'он': 0, 'не': 0, 'только': 0}\n",
      "{'и': 1, 'ты': 1, 'я': 1, 'он': 0, 'не': 0, 'только': 0}\n",
      "{'и': 1, 'ты': 0, 'я': 3, 'он': 0, 'не': 0, 'только': 1}\n",
      "{'и': 0, 'ты': 0, 'я': 1, 'он': 0, 'не': 1, 'только': 1}\n",
      "{'и': 0, 'ты': 0, 'я': 0, 'он': 1, 'не': 0, 'только': 0}\n"
     ]
    }
   ],
   "source": [
    "print(numOfWords1)\n",
    "print(numOfWords2)\n",
    "print(numOfWords3)\n",
    "print(numOfWords4)\n",
    "print(numOfWords5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "b15aeb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict, bagOfWords):\n",
    "    tfDict = {}\n",
    "    bagOfWordsCount = len(bagOfWords)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count / float(bagOfWordsCount)\n",
    "    return tfDict\n",
    "\n",
    "tf1 = computeTF(numOfWords1, doc1)\n",
    "tf2 = computeTF(numOfWords2, doc2)\n",
    "tf3 = computeTF(numOfWords3, doc3)\n",
    "tf4 = computeTF(numOfWords4, doc4)\n",
    "tf5 = computeTF(numOfWords5, doc5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "75d257a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term frequency in doc1: {'и': 0.3333333333333333, 'ты': 0.3333333333333333, 'я': 0.3333333333333333, 'он': 0.0, 'не': 0.0, 'только': 0.0}\n",
      "Term frequency in doc2: {'и': 0.3333333333333333, 'ты': 0.3333333333333333, 'я': 0.3333333333333333, 'он': 0.0, 'не': 0.0, 'только': 0.0}\n",
      "Term frequency in doc3: {'и': 0.2, 'ты': 0.0, 'я': 0.6, 'он': 0.0, 'не': 0.0, 'только': 0.2}\n",
      "Term frequency in doc4: {'и': 0.0, 'ты': 0.0, 'я': 0.3333333333333333, 'он': 0.0, 'не': 0.3333333333333333, 'только': 0.3333333333333333}\n",
      "Term frequency in doc5: {'и': 0.0, 'ты': 0.0, 'я': 0.0, 'он': 1.0, 'не': 0.0, 'только': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print('Term frequency in doc1:', tf1)\n",
    "print('Term frequency in doc2:', tf2)\n",
    "print('Term frequency in doc3:', tf3)\n",
    "print('Term frequency in doc4:', tf4)\n",
    "print('Term frequency in doc5:', tf5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "d287022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(documents):\n",
    "    import math\n",
    "    N = len(documents)\n",
    "    \n",
    "    idfDict = dict.fromkeys(documents[0].keys(), 0)\n",
    "    for document in documents:\n",
    "        for word, val in document.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log(N / float(val))\n",
    "    return idfDict\n",
    "\n",
    "idfs = computeIDF([numOfWords1, numOfWords2, numOfWords3, numOfWords4, numOfWords5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "f9e9eb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(tfBagOfWords, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBagOfWords.items():\n",
    "        tfidf[word] = val * idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "9959d2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>и</th>\n",
       "      <th>ты</th>\n",
       "      <th>я</th>\n",
       "      <th>он</th>\n",
       "      <th>не</th>\n",
       "      <th>только</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.170275</td>\n",
       "      <td>0.30543</td>\n",
       "      <td>0.074381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.170275</td>\n",
       "      <td>0.30543</td>\n",
       "      <td>0.074381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.102165</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.133886</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.074381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.536479</td>\n",
       "      <td>0.305430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          и       ты         я        он        не    только\n",
       "0  0.170275  0.30543  0.074381  0.000000  0.000000  0.000000\n",
       "1  0.170275  0.30543  0.074381  0.000000  0.000000  0.000000\n",
       "2  0.102165  0.00000  0.133886  0.000000  0.000000  0.183258\n",
       "3  0.000000  0.00000  0.074381  0.000000  0.536479  0.305430\n",
       "4  0.000000  0.00000  0.000000  1.609438  0.000000  0.000000"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf1 = computeTFIDF(tf1, idfs)\n",
    "tfidf2 = computeTFIDF(tf2, idfs)\n",
    "tfidf3 = computeTFIDF(tf3, idfs)\n",
    "tfidf4 = computeTFIDF(tf4, idfs)\n",
    "tfidf5 = computeTFIDF(tf5, idfs)\n",
    "\n",
    "df = pd.DataFrame([tfidf1, tfidf2, tfidf3, tfidf4, tfidf5])\n",
    "df.head()\n",
    "#итоговая таблица"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0920c76",
   "metadata": {},
   "source": [
    "### Задание 3\n",
    "Обучите 2 любых разных классификатора из семинара. Предскажите токсичность для текстов из тестовой выборки (используйте одну и ту же выборку для обоих классификаторов) и найдите 10 самых токсичных для каждого из классификаторов. Сравните получаемые тексты - какие тексты совпадают, какие отличаются, правда ли тексты токсичные?\n",
    "\n",
    "Требования к классификаторам:\n",
    "а) один должен использовать CountVectorizer, другой TfidfVectorizer\n",
    "б) у векторазера должны быть вручную заданы как минимум 5 параметров\n",
    "в) у классификатора должно быть задано вручную как минимум 2 параметра\n",
    "г) f1 мера каждого из классификаторов должна быть минимум 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bab9a72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  toxic\n",
       "0               Верблюдов-то за что? Дебилы, бл...\\n    1.0\n",
       "1  Хохлы, это отдушина затюканого россиянина, мол...    1.0\n",
       "2                          Собаке - собачья смерть\\n    1.0\n",
       "3  Страницу обнови, дебил. Это тоже не оскорблени...    1.0\n",
       "4  тебя не убедил 6-страничный пдф в том, что Скр...    1.0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('labeled.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6cc5d27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.1, shuffle=True)\n",
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4d77c010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.88      0.88       906\n",
      "         1.0       0.80      0.80      0.80       536\n",
      "\n",
      "    accuracy                           0.85      1442\n",
      "   macro avg       0.84      0.84      0.84      1442\n",
      "weighted avg       0.85      0.85      0.85      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#логистическая регрессия с TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(input='content', binary=False, ngram_range=(1,1), min_df = 5, lowercase = True)\n",
    "X = vectorizer.fit_transform(train.comment)\n",
    "X_test = vectorizer.transform(test.comment) \n",
    "y = train.toxic.values\n",
    "y_test = test.toxic.values\n",
    "\n",
    "clf = LogisticRegression(C=0.9, class_weight='balanced')\n",
    "clf.fit(X, y)\n",
    "preds = clf.predict(X_test)\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ec9ad947",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-95-4359c0ba8e6d>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['probabilityTfIdf'] = [row[1] for row in probas]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "      <th>probabilityTfIdf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>261</td>\n",
       "      <td>Ты бы и к собаке пристроился.\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>6423</td>\n",
       "      <td>Росстат сравнил уровень счастья: чувства, здор...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10848</td>\n",
       "      <td>магнит ГФ покрыли краской) много денег\\n</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>4645</td>\n",
       "      <td>просто не либераст бездомный.\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>9395</td>\n",
       "      <td>Я пошёл учиться на программиста в 29. Звездой ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>6738</td>\n",
       "      <td>Это серийные устройства, используются для комм...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>14373</td>\n",
       "      <td>Прощай, немытая Россия, Страна рабов, страна г...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>9422</td>\n",
       "      <td>Одна из причина КЗ - плохой контакт в соединен...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>9517</td>\n",
       "      <td>Обычно так и делают, просто почистили и хорош,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.988898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>12931</td>\n",
       "      <td>Вы шавки обыкновенные, которые за кость растер...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.987354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                            comment  toxic  \\\n",
       "545     261                    Ты бы и к собаке пристроился.\\n    1.0   \n",
       "856    6423  Росстат сравнил уровень счастья: чувства, здор...    0.0   \n",
       "13    10848           магнит ГФ покрыли краской) много денег\\n    0.0   \n",
       "48     4645                    просто не либераст бездомный.\\n    1.0   \n",
       "174    9395  Я пошёл учиться на программиста в 29. Звездой ...    0.0   \n",
       "1334   6738  Это серийные устройства, используются для комм...    0.0   \n",
       "651   14373  Прощай, немытая Россия, Страна рабов, страна г...    1.0   \n",
       "164    9422  Одна из причина КЗ - плохой контакт в соединен...    0.0   \n",
       "1171   9517  Обычно так и делают, просто почистили и хорош,...    0.0   \n",
       "470   12931  Вы шавки обыкновенные, которые за кость растер...    1.0   \n",
       "\n",
       "      probabilityTfIdf  \n",
       "545           0.999130  \n",
       "856           0.999130  \n",
       "13            0.995522  \n",
       "48            0.993006  \n",
       "174           0.992886  \n",
       "1334          0.992759  \n",
       "651           0.992079  \n",
       "164           0.991625  \n",
       "1171          0.988898  \n",
       "470           0.987354  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict_proba возвращает вероятности классов\n",
    "# в левой колонке вероятность 0 (нетокстичности)\n",
    "# в правой - вероятность 1 (токсичности)\n",
    "# логистическая регрессия\n",
    "import numpy as np\n",
    "\n",
    "probasTfIdf = clf.predict_proba(X_test)\n",
    "test['probabilityTfIdf'] = [row[1] for row in probas]\n",
    "test.sort_values(by='probabilityTfIdf', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "10128c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.96      0.92       981\n",
      "         1.0       0.89      0.73      0.80       461\n",
      "\n",
      "    accuracy                           0.88      1442\n",
      "   macro avg       0.89      0.84      0.86      1442\n",
      "weighted avg       0.89      0.88      0.88      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Наивный байесовский классификатор с CountVectorizer\n",
    "vectorizer = CountVectorizer(input='content', binary=False, ngram_range=(1,1), min_df = 1, lowercase = True)\n",
    "X1 = vectorizer.fit_transform(train.comment)\n",
    "X1_test = vectorizer.transform(test.comment) \n",
    "y1 = train.toxic.values\n",
    "y1_test = test.toxic.values\n",
    "\n",
    "clf = MultinomialNB(alpha=1., fit_prior = False)\n",
    "clf.fit(X1, y1)\n",
    "preds = clf.predict(X1_test)\n",
    "\n",
    "print(classification_report(y1_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e97fa388",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-97-2dd3cca1630e>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['probabilityBayes'] = [row[1] for row in probasBayes]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "      <th>probabilityTfIdf</th>\n",
       "      <th>probabilityBayes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>723</td>\n",
       "      <td>Как известно, у Укр ины (т.е. окр ины), слепле...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.535101</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>41</td>\n",
       "      <td>Ну давай разберём всё тобой написанное. Бляядь...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.324793</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>14400</td>\n",
       "      <td>Не зря, вас, хохлов, свиньями кличут. Вы и ест...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.140872</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>14224</td>\n",
       "      <td>01:30 о встрече с Чубайсом 02:40 как Шарий защ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.459606</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>2781</td>\n",
       "      <td>Пошла нахуй свинья. Хохла на штык! Хороший хох...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.263822</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>872</td>\n",
       "      <td>Зальете шебм? Вот этот кун. Говорит, будто зая...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.723205</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>1699</td>\n",
       "      <td>можете назвать ХОТЬ ОДНУ блядь нацию, которая ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.097269</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>768</td>\n",
       "      <td>Хоть ты и дегенерат, но ты прав. В том, что ты...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.385785</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>639</td>\n",
       "      <td>Аааа, ясно как ты знаешь США, наверное по твое...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.517819</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>1738</td>\n",
       "      <td>Гандоны - это ты и твой хозяин - пидорас-приго...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.108654</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                            comment  toxic  \\\n",
       "843     723  Как известно, у Укр ины (т.е. окр ины), слепле...    1.0   \n",
       "257      41  Ну давай разберём всё тобой написанное. Бляядь...    1.0   \n",
       "796   14400  Не зря, вас, хохлов, свиньями кличут. Вы и ест...    1.0   \n",
       "25    14224  01:30 о встрече с Чубайсом 02:40 как Шарий защ...    1.0   \n",
       "935    2781  Пошла нахуй свинья. Хохла на штык! Хороший хох...    1.0   \n",
       "846     872  Зальете шебм? Вот этот кун. Говорит, будто зая...    1.0   \n",
       "870    1699  можете назвать ХОТЬ ОДНУ блядь нацию, которая ...    1.0   \n",
       "412     768  Хоть ты и дегенерат, но ты прав. В том, что ты...    1.0   \n",
       "1012    639  Аааа, ясно как ты знаешь США, наверное по твое...    0.0   \n",
       "384    1738  Гандоны - это ты и твой хозяин - пидорас-приго...    1.0   \n",
       "\n",
       "      probabilityTfIdf  probabilityBayes  \n",
       "843           0.535101               1.0  \n",
       "257           0.324793               1.0  \n",
       "796           0.140872               1.0  \n",
       "25            0.459606               1.0  \n",
       "935           0.263822               1.0  \n",
       "846           0.723205               1.0  \n",
       "870           0.097269               1.0  \n",
       "412           0.385785               1.0  \n",
       "1012          0.517819               1.0  \n",
       "384           0.108654               1.0  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict_proba возвращает вероятности классов\n",
    "# в левой колонке вероятность 0 (нетокстичности)\n",
    "# в правой - вероятность 1 (токсичности)\n",
    "# Наивный байесовский классификатор\n",
    "\n",
    "probasBayes = clf.predict_proba(X1_test)\n",
    "test['probabilityBayes'] = [row[1] for row in probasBayes]\n",
    "test.sort_values(by='probabilityBayes', ascending=False)[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d12dfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#найдите 10 самых токсичных для каждого из классификаторов. \n",
    "#Сравните получаемые тексты - какие тексты совпадают, какие отличаются, правда ли тексты токсичные?\n",
    "\n",
    "#Ни один текст из десяти для двух моделей не совпал. У Байеса 10 самых токсичных получились точнее (см. рисунок).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "24f4bc7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ibb.co/RyrqfYf/image.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://i.ibb.co/RyrqfYf/image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "133b1bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ibb.co/vLX0xcb/1.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://i.ibb.co/vLX0xcb/1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07b42af",
   "metadata": {},
   "source": [
    "### Задание 1 \n",
    "У векторайзеров в sklearn есть встроенная токенизация на регулярных выражениях. Найдите способо заменить её на кастомную токенизацию\n",
    "\n",
    "Обучите векторайзер с дефолтной токенизацией и с токенизацией razdel.tokenize. Обучите классификатор с каждым из векторизаторов. Сравните метрики и выберете победителя.\n",
    "\n",
    "(в вашей тетрадке должен быть код обучения и все метрики; если вы сдаете в .py файлах то сохраните полученные метрики в отдельном файле или в комментариях)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5f2cd410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<27857x69451 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 435770 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# векторайзер с razdel.tokenize\n",
    "\n",
    "f = open('labeled.csv', 'r', encoding='UTF-8')\n",
    "from razdel import tokenize\n",
    "\n",
    "def my_tokenizer(text):\n",
    "    tokens = list(tokenize(text))\n",
    "    token = [t.text for t in tokens]\n",
    "    return token\n",
    "    \n",
    "vectorizer_custom = TfidfVectorizer(tokenizer=my_tokenizer)\n",
    "X_custom = vectorizer_custom.fit_transform(f)\n",
    "X_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "97180070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<27857x68425 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 320937 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# дефолтный векторайзер\n",
    "\n",
    "f = open('labeled.csv', 'r', encoding='UTF-8')\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(f)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c6404e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('labeled.csv')\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.1, shuffle=True)\n",
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fcbeb362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.89      0.89       941\n",
      "         1.0       0.80      0.80      0.80       501\n",
      "\n",
      "    accuracy                           0.86      1442\n",
      "   macro avg       0.85      0.85      0.85      1442\n",
      "weighted avg       0.86      0.86      0.86      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# классификатор с дефолтным векторайзером\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(train.comment)\n",
    "X_test = vectorizer.transform(test.comment) \n",
    "y = train.toxic.values\n",
    "y_test = test.toxic.values\n",
    "\n",
    "clf = LogisticRegression(C=0.9, class_weight='balanced')\n",
    "clf.fit(X, y)\n",
    "preds = clf.predict(X_test)\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c1c30d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.88      0.88       941\n",
      "         1.0       0.78      0.78      0.78       501\n",
      "\n",
      "    accuracy                           0.85      1442\n",
      "   macro avg       0.83      0.83      0.83      1442\n",
      "weighted avg       0.85      0.85      0.85      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# классификатор с векторайзером с razdel.tokenize\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=my_tokenizer)\n",
    "X = vectorizer.fit_transform(train.comment)\n",
    "X_test = vectorizer.transform(test.comment) \n",
    "y = train.toxic.values\n",
    "y_test = test.toxic.values\n",
    "\n",
    "clf = LogisticRegression(C=0.9, class_weight='balanced')\n",
    "clf.fit(X, y)\n",
    "preds = clf.predict(X_test)\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226c469c",
   "metadata": {},
   "source": [
    "По всем метрикам дефолтный векторайзер лучше, хотя и ненамного."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605aecb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
