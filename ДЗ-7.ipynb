{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9932cad5",
   "metadata": {},
   "source": [
    "## Задание 1 Реализовать алгоритм Леска и проверить его на реальном датасете (8 баллов)\n",
    "Ворднет можно использовать для дизамбигуации. Самый простой алгоритм дизамбигуации - алгоритм Леска. В нём нужное значение слова находится через пересечение слов контекста, в котором употреблено это слово, с определениями значений слова из ворднета. Значение с максимальным пересечением - нужное.\n",
    "\n",
    "Реализуйте его"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "567b66ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\addre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d72aeeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from string import punctuation\n",
    "import json, os, re, sys\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "import gensim\n",
    "import pandas as pd\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "morph = MorphAnalyzer()\n",
    "punct = punctuation+'«»—…“”*№–'\n",
    "stops = set(stopwords.words('russian'))\n",
    "\n",
    "def normalize(text):\n",
    "    \n",
    "    words = [token.text.strip(punct) for token in list(razdel_tokenize(text))]\n",
    "    words = [morph.parse(word)[0].normal_form for word in words if word and word not in stops]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e524ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lesk(word, sentence):\n",
    "    bestsense = 0\n",
    "    maxoverlap = 0\n",
    "    synsets = wn.synsets(word)\n",
    "    \n",
    "    for i, syns in enumerate(synsets):\n",
    "        senses = word_tokenize(syns.definition())\n",
    "        overlap = len(set(senses).intersection(set(sentence)))\n",
    "        if overlap > maxoverlap:\n",
    "            maxoverlap = overlap\n",
    "            bestsense = i\n",
    "        \n",
    "    return bestsense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "78d15166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_in_context(words, n=3):\n",
    "    neighbours = [] \n",
    "    for i in range(len(words)):\n",
    "        if i-n<0:\n",
    "            words_after = words[i+1:i+n+1]\n",
    "            words_before = words[0:i]\n",
    "            ws = words_before + words_after\n",
    "            lst = list([words[i], ws])\n",
    "            neighbours.append(lst)   \n",
    "        \n",
    "        else:\n",
    "            words_after = words[i+1:i+n+1]\n",
    "            words_before = words[i-n:i]\n",
    "            ws = words_before + words_after\n",
    "            lst = list([words[i], ws])\n",
    "            neighbours.append(lst)\n",
    "    return neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4dde23ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_wsd = []\n",
    "\n",
    "corpus = open('corpus_wsd_50k.txt').read().split('\\n\\n')\n",
    "for sent in corpus:\n",
    "    corpus_wsd.append([s.split('\\t') for s in sent.split('\\n')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7d877710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['', 'have', 'Have'],\n",
       " ['', 'you', 'you'],\n",
       " ['permit%2:41:00::', 'permit', 'permitted'],\n",
       " ['', 'it', 'it'],\n",
       " ['', 'to', 'to'],\n",
       " ['become%2:42:01::', 'become', 'become'],\n",
       " ['', 'a', 'a'],\n",
       " ['giveaway%1:21:00::', 'giveaway', 'giveaway'],\n",
       " ['program%1:09:01::', 'program', 'program'],\n",
       " ['rather%4:02:02::', 'rather', 'rather'],\n",
       " ['', 'than', 'than'],\n",
       " ['', 'one', 'one'],\n",
       " ['', 'that', 'that'],\n",
       " ['have%2:42:00::', 'have', 'has'],\n",
       " ['', 'the', 'the'],\n",
       " ['goal%1:09:00::', 'goal', 'goal'],\n",
       " ['', 'of', 'of'],\n",
       " ['improved%3:00:00::', 'improved', 'improved'],\n",
       " ['employee%1:18:00::', 'employee', 'employee'],\n",
       " ['morale%1:26:00::', 'morale', 'morale'],\n",
       " ['', 'and', 'and'],\n",
       " ['', ',', ','],\n",
       " ['consequently%4:02:00::', 'consequently', 'consequently'],\n",
       " ['', ',', ','],\n",
       " ['increased%3:00:00::', 'increased', 'increased'],\n",
       " ['productivity%1:07:00::', 'productivity', 'productivity'],\n",
       " ['', '?', '?']]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_wsd[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dfa676e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_wsd_short = corpus_wsd[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9b7937b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_list = []\n",
    "lesk_list = []\n",
    "\n",
    "for i, sent in enumerate(corpus_wsd_short):\n",
    "    if sent[0][0]:\n",
    "        context = []\n",
    "        \n",
    "        for w in sent:\n",
    "            if '%' in w[0]:\n",
    "                context.append(w[1])\n",
    "                wn_var = wn.lemma_from_key(w[0]).synset()\n",
    "                wordnet_list.append(wn_var)\n",
    "        \n",
    "        words_in_context = get_words_in_context(context, n=3)\n",
    "        \n",
    "        for st in words_in_context:\n",
    "            i = lesk(st[0], st[1])\n",
    "            lesk_var = wn.synsets(st[0])[i]\n",
    "            lesk_list.append(lesk_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a07bf7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'wordnet': wordnet_list, 'lesk': lesk_list}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b897399b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wordnet</th>\n",
       "      <th>lesk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Synset('be.v.01')</td>\n",
       "      <td>Synset('beryllium.n.01')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Synset('bigger.s.01')</td>\n",
       "      <td>Synset('bigger.s.01')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Synset('fancy.a.01')</td>\n",
       "      <td>Synset('fancy.n.02')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Synset('truly.r.01')</td>\n",
       "      <td>Synset('truly.r.01')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Synset('want.v.02')</td>\n",
       "      <td>Synset('need.n.01')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Synset('exist.v.01')</td>\n",
       "      <td>Synset('beryllium.n.01')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Synset('other.a.01')</td>\n",
       "      <td>Synset('other.a.01')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Synset('cheap.a.01')</td>\n",
       "      <td>Synset('cheap.a.01')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Synset('communication.n.01')</td>\n",
       "      <td>Synset('communication.n.01')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Synset('technique.n.01')</td>\n",
       "      <td>Synset('technique.n.01')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        wordnet                          lesk\n",
       "0             Synset('be.v.01')      Synset('beryllium.n.01')\n",
       "1         Synset('bigger.s.01')         Synset('bigger.s.01')\n",
       "2          Synset('fancy.a.01')          Synset('fancy.n.02')\n",
       "3          Synset('truly.r.01')          Synset('truly.r.01')\n",
       "4           Synset('want.v.02')           Synset('need.n.01')\n",
       "5          Synset('exist.v.01')      Synset('beryllium.n.01')\n",
       "6          Synset('other.a.01')          Synset('other.a.01')\n",
       "7          Synset('cheap.a.01')          Synset('cheap.a.01')\n",
       "8  Synset('communication.n.01')  Synset('communication.n.01')\n",
       "9      Synset('technique.n.01')      Synset('technique.n.01')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "582f4274",
   "metadata": {},
   "outputs": [],
   "source": [
    "match = np.zeros(df.shape[0])\n",
    "\n",
    "for i, syn in enumerate(df['wordnet'].values):\n",
    "    if df['lesk'][i] == syn:\n",
    "        match[i] = 1\n",
    "    else:\n",
    "        match[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "94835e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wordnet</th>\n",
       "      <th>lesk</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Synset('be.v.01')</td>\n",
       "      <td>Synset('beryllium.n.01')</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Synset('bigger.s.01')</td>\n",
       "      <td>Synset('bigger.s.01')</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Synset('fancy.a.01')</td>\n",
       "      <td>Synset('fancy.n.02')</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Synset('truly.r.01')</td>\n",
       "      <td>Synset('truly.r.01')</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Synset('want.v.02')</td>\n",
       "      <td>Synset('need.n.01')</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Synset('exist.v.01')</td>\n",
       "      <td>Synset('beryllium.n.01')</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Synset('other.a.01')</td>\n",
       "      <td>Synset('other.a.01')</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Synset('cheap.a.01')</td>\n",
       "      <td>Synset('cheap.a.01')</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Synset('communication.n.01')</td>\n",
       "      <td>Synset('communication.n.01')</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Synset('technique.n.01')</td>\n",
       "      <td>Synset('technique.n.01')</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        wordnet                          lesk  match\n",
       "0             Synset('be.v.01')      Synset('beryllium.n.01')    0.0\n",
       "1         Synset('bigger.s.01')         Synset('bigger.s.01')    1.0\n",
       "2          Synset('fancy.a.01')          Synset('fancy.n.02')    0.0\n",
       "3          Synset('truly.r.01')          Synset('truly.r.01')    1.0\n",
       "4           Synset('want.v.02')           Synset('need.n.01')    0.0\n",
       "5          Synset('exist.v.01')      Synset('beryllium.n.01')    0.0\n",
       "6          Synset('other.a.01')          Synset('other.a.01')    1.0\n",
       "7          Synset('cheap.a.01')          Synset('cheap.a.01')    1.0\n",
       "8  Synset('communication.n.01')  Synset('communication.n.01')    1.0\n",
       "9      Synset('technique.n.01')      Synset('technique.n.01')    1.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['match'] = match\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6a117520",
   "metadata": {},
   "outputs": [],
   "source": [
    "true = df[df['match'] == 1].shape[0]\n",
    "al = df['match'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "88c0db12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5414615675880349\n"
     ]
    }
   ],
   "source": [
    "print(true/al)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
